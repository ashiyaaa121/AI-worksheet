{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaK4KgGL83uRtHTtn8h8HH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiyaaa121/AI-worksheet/blob/main/Workshop5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LIRHO5NNMP2o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Custom function to split data into training and testing sets\n",
        "def train_test_split(X, y, test_size=0.3, random_state=42):\n",
        "\n",
        "    # Set random seed so that results are reproducible\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Create an array of indices based on number of samples in X\n",
        "    indices = np.arange(X.shape[0])\n",
        "\n",
        "    # Shuffle the indices randomly\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Calculate number of samples for the test set\n",
        "    test_split_size = int(len(X) * test_size)\n",
        "\n",
        "    # Split indices into training and testing\n",
        "    train_indices = indices[:test_split_size]\n",
        "    test_indices = indices[test_split_size:]\n",
        "\n",
        "    # Create training and testing datasets using the indices\n",
        "    X_train, X_test = X[train_indices], X[test_indices]\n",
        "    y_train, y_test = y[train_indices], y[test_indices]\n",
        "\n",
        "    # Return the split datasets\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(X, Y, W):\n",
        "\n",
        "    # Compute predicted values\n",
        "    y_pred = np.matmul(X, W)\n",
        "\n",
        "    # Calculate squared error for each data point\n",
        "    squared_errors = [(y_pred[i] - Y[i]) ** 2 for i in range(len(Y))]\n",
        "\n",
        "    # Number of samples\n",
        "    m = len(Y)\n",
        "\n",
        "    # Compute mean squared error cost\n",
        "    cost = sum(squared_errors) / (2 * m)\n",
        "\n",
        "    return cost\n",
        "\n"
      ],
      "metadata": {
        "id": "dxYlw96bvU4d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "\n",
        "    # Store cost value for each iteration\n",
        "    cost_history = [0] * iterations\n",
        "\n",
        "    # Number of training examples\n",
        "    m = len(Y)\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        # Step 1: Compute predicted values\n",
        "        Y_pred = np.matmul(X, W)\n",
        "\n",
        "        # Step 2: Calculate error (prediction - actual)\n",
        "        loss = Y_pred - Y\n",
        "\n",
        "        # Step 3: Compute gradient\n",
        "        dw = (1 / m) * np.matmul(X.T, loss)\n",
        "\n",
        "        # Step 4: Update weights\n",
        "        W = W - alpha * dw\n",
        "\n",
        "        # Step 5: Calculate cost with updated weights\n",
        "        cost_history[iteration] = cost_function(X, Y, W)\n",
        "\n",
        "    return W, cost_history\n"
      ],
      "metadata": {
        "id": "YbiZ0NOs0kmB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - RMSE\n",
        "def rmse(Y, Y_pred):\n",
        "\n",
        "    # Calculate squared error\n",
        "    loss = (Y - Y_pred) ** 2\n",
        "\n",
        "    # Compute root mean squared error\n",
        "    rmse_value = np.sqrt(sum(loss) / len(Y))\n",
        "\n",
        "    return rmse_value\n"
      ],
      "metadata": {
        "id": "jZpDODrh1Tul"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - RÂ²\n",
        "def r2(Y, Y_pred):\n",
        "\n",
        "    # Compute mean of actual values\n",
        "    mean_y = np.mean(Y)\n",
        "\n",
        "    # Total sum of squares\n",
        "    ss_tot = (Y - mean_y) ** 2\n",
        "\n",
        "    # Residual sum of squares\n",
        "    ss_res = (Y - Y_pred) ** 2\n",
        "\n",
        "    # Compute R-squared score\n",
        "    r2_value = 1 - (sum(ss_res) / sum(ss_tot))\n",
        "\n",
        "    return r2_value\n"
      ],
      "metadata": {
        "id": "UJJw1W9V1c_4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    # Step 1: Load dataset\n",
        "    data = pd.read_csv('student.csv')\n",
        "\n",
        "    # Step 2: Separate features (X) and target (Y)\n",
        "    X = data[['Math', 'Reading']].values     # Input features\n",
        "    Y = data['Writing'].values               # Output target\n",
        "\n",
        "    # Step 3: Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Step 4: Initialize weights, learning rate, and iterations\n",
        "    W = np.zeros(X_train.shape[1])   # Initialize weights to zero\n",
        "    alpha = 0.0001                   # Learning rate\n",
        "    iterations = 1000                # Number of iterations\n",
        "\n",
        "    # Step 5: Train model using gradient descent\n",
        "    W_optimal, cost_history = gradient_descent(\n",
        "        X_train, Y_train, W, alpha, iterations\n",
        "    )\n",
        "\n",
        "    # Step 6: Predict on test data\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "    # Step 7: Evaluate model performance\n",
        "    model_rmse = rmse(Y_test, Y_pred)\n",
        "    model_r2 = r2(Y_test, Y_pred)\n",
        "\n",
        "    # Step 8: Display results\n",
        "    print(\"Final Weights:\", W_optimal)\n",
        "    print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "    print(\"RMSE on Test Set:\", model_rmse)\n",
        "    print(\"R-Squared on Test Set:\", model_r2)\n",
        "\n",
        "\n",
        "# Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzUNxYA11pRn",
        "outputId": "a7161e2c-26f0-4b07-e610-b5f072166daf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.10797386 0.88521888]\n",
            "Cost History (First 10 iterations): [np.float64(19.24614259802574), np.float64(17.713592777548037), np.float64(17.657533670638085), np.float64(17.602841761264234), np.float64(17.548621706343425), np.float64(17.49486890572484), np.float64(17.44157933241292), np.float64(17.38874899443804), np.float64(17.336373934232473), np.float64(17.28445022833376)]\n",
            "RMSE on Test Set: 4.568899888949264\n",
            "R-Squared on Test Set: 0.9082364822828619\n"
          ]
        }
      ]
    }
  ]
}